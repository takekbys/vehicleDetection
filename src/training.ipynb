{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numpy.random import rand, randint, ranf, randn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy.matlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み、分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>type</th>\n",
       "      <th>truncated</th>\n",
       "      <th>occluded</th>\n",
       "      <th>alpha</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>right</th>\n",
       "      <th>bottom</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>rotation_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004863</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>572.44</td>\n",
       "      <td>181.56</td>\n",
       "      <td>611.95</td>\n",
       "      <td>219.71</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>2.08</td>\n",
       "      <td>33.40</td>\n",
       "      <td>-1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004863</td>\n",
       "      <td>Tram</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>498.85</td>\n",
       "      <td>149.49</td>\n",
       "      <td>551.40</td>\n",
       "      <td>204.32</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.60</td>\n",
       "      <td>15.21</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>2.16</td>\n",
       "      <td>55.58</td>\n",
       "      <td>-1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004863</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.12</td>\n",
       "      <td>56.46</td>\n",
       "      <td>195.89</td>\n",
       "      <td>220.78</td>\n",
       "      <td>260.91</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.71</td>\n",
       "      <td>4.36</td>\n",
       "      <td>-12.68</td>\n",
       "      <td>2.15</td>\n",
       "      <td>19.71</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004863</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>321.08</td>\n",
       "      <td>188.65</td>\n",
       "      <td>383.52</td>\n",
       "      <td>221.93</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.71</td>\n",
       "      <td>3.89</td>\n",
       "      <td>-12.88</td>\n",
       "      <td>2.34</td>\n",
       "      <td>36.20</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004863</td>\n",
       "      <td>DontCare</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>280.40</td>\n",
       "      <td>183.35</td>\n",
       "      <td>291.90</td>\n",
       "      <td>212.56</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1000.00</td>\n",
       "      <td>-1000.00</td>\n",
       "      <td>-1000.00</td>\n",
       "      <td>-10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  img_name      type  truncated  occluded  alpha    left     top   right  \\\n",
       "0   004863       Car        0.0         0  -1.55  572.44  181.56  611.95   \n",
       "1   004863      Tram        0.0         0  -1.48  498.85  149.49  551.40   \n",
       "2   004863       Car        0.0         1   2.12   56.46  195.89  220.78   \n",
       "3   004863       Car        0.0         0   1.92  321.08  188.65  383.52   \n",
       "4   004863  DontCare       -1.0        -1 -10.00  280.40  183.35  291.90   \n",
       "\n",
       "   bottom  height  width  length        x        y        z  rotation_y  \n",
       "0  219.71    1.66   1.73    3.05    -0.82     2.08    33.40       -1.57  \n",
       "1  204.32    3.62   2.60   15.21    -6.27     2.16    55.58       -1.60  \n",
       "2  260.91    1.47   1.71    4.36   -12.68     2.15    19.71        1.55  \n",
       "3  221.93    1.52   1.71    3.89   -12.88     2.34    36.20        1.58  \n",
       "4  212.56   -1.00  -1.00   -1.00 -1000.00 -1000.00 -1000.00      -10.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../data/training/'\n",
    "ANNOTATIONS = PATH + \"label_2/annotations_list.pkl\"\n",
    "annotations_list = pd.read_pickle(\"../data/training/label_2/annotations_list.pkl\")\n",
    "annotations_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_list has 7106 images.\n",
      "val_list has 375 images.\n"
     ]
    }
   ],
   "source": [
    "img_list = list(annotations_list[\"img_name\"].unique())\n",
    "train_list, val_list = train_test_split(img_list, test_size=0.05, shuffle=True, random_state=0)\n",
    "print(\"train_list has\", len(train_list), \"images.\")\n",
    "print(\"val_list has\", len(val_list), \"images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb89a4fcd30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_heatmap(h, w, h_center, w_center, sigma=2):\n",
    "    w_range = np.arange(0,w)-w_center\n",
    "    w_range = np.matlib.repmat(w_range, h, 1)\n",
    "    h_range = np.arange(0,h)-h_center\n",
    "    h_range = h_range.reshape(h,1)\n",
    "    h_range = np.matlib.repmat(h_range, 1, w)\n",
    "    Yxyc = np.exp(-(w_range**2+h_range**2)/sigma)\n",
    "    return Yxyc.T\n",
    "\n",
    "hm = get_heatmap(10, 20, 5, 10)\n",
    "plt.imshow(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2P(l):\n",
    "    P_elem = l.split()[1:]\n",
    "    P = np.array(P_elem, dtype=np.float).reshape(3,-1)\n",
    "    return P\n",
    "\n",
    "def readCalib(calib_name, calib_path):\n",
    "    calib_name = calib_path + calib_name + \".txt\"\n",
    "    with open(calib_name) as f:\n",
    "        P0 = line2P(f.readline())\n",
    "        P1 = line2P(f.readline())\n",
    "        P2 = line2P(f.readline())\n",
    "        P3 = line2P(f.readline())\n",
    "        R0_rect = line2P(f.readline())\n",
    "        Tr_velo_to_cam = line2P(f.readline())\n",
    "        Tr_imu_to_velo = line2P(f.readline())\n",
    "    return P0, P1, P2, P3, R0_rect, Tr_velo_to_cam, Tr_imu_to_velo\n",
    "\n",
    "def projectToImage(pts3D, P):\n",
    "    P = np.array(P)\n",
    "    \n",
    "    ones = np.ones([1,pts3D.shape[1]])\n",
    "    pts3D = np.append(pts3D, ones, axis=0)\n",
    "    pts2D = np.dot(P, pts3D)\n",
    "    pts2D[0] /= pts2D[2]\n",
    "    pts2D[1] /= pts2D[2]\n",
    "    pts2D = np.delete(pts2D, obj=2, axis=0)\n",
    "    return pts2D\n",
    "\n",
    "def selectVisibleSurface(corner3D):\n",
    "    # 直方体の8点から、隠れた点を除いて出力する\n",
    "    face_mask = np.array([[1,1,0,0,1,1,0,0], # front\n",
    "                          [0,1,1,0,0,1,1,0], # right\n",
    "                          [0,0,1,1,0,0,1,1], # back\n",
    "                          [1,0,0,1,1,0,0,1]  # left\n",
    "                         ])\n",
    "\n",
    "    # 直方体の中心位置を計算\n",
    "    c_rectangular = np.sum(corner3D, axis=1)/8\n",
    "\n",
    "    # 各面の法線と面からカメラへの直線がなす角度が90度以下であればその面は見える\n",
    "    surface_coord3D = np.zeros([3,4])\n",
    "    visible_flag = np.zeros(4)\n",
    "    for i in range(4):\n",
    "        p_in_plane = corner3D * face_mask[i] # 平面の4つの頂点\n",
    "        c_plane = np.sum(p_in_plane, axis=1)/4 # 平面の中心\n",
    "        normal = c_plane - c_rectangular# 平面の法線ベクトル\n",
    "        c_to_O = -c_plane # 平面の中心からカメラ位置へのベクトル\n",
    "        surface_coord3D[:,i] = c_plane\n",
    "        if np.dot(c_to_O, normal)>0:\n",
    "            visible_flag[i] = 1\n",
    "    return visible_flag==1, surface_coord3D\n",
    "\n",
    "def selectVisiblePoint(corner3D):\n",
    "    # 直方体の8点から、隠れた点を除いて出力する\n",
    "    face_mask = np.array([[1,1,0,0,1,1,0,0], # front\n",
    "                          [0,1,1,0,0,1,1,0], # right\n",
    "                          [0,0,1,1,0,0,1,1], # back\n",
    "                          [1,0,0,1,1,0,0,1]  # left\n",
    "                         ])\n",
    "\n",
    "    # 直方体の中心位置を計算\n",
    "    c_rectangular = np.sum(corner3D, axis=1)/8\n",
    "\n",
    "    # 各面の法線と面からカメラへの直線がなす角度が90度以下であればその面は見える\n",
    "    visible_mask = np.zeros(8)\n",
    "    for i in range(4):\n",
    "        p_in_plane = corner3D * face_mask[i] # 平面の4つの頂点\n",
    "        c_plane = np.sum(p_in_plane, axis=1)/4 # 平面の中心\n",
    "        normal = c_plane - c_rectangular# 平面の法線ベクトル\n",
    "        c_to_O = -c_plane # 平面の中心からカメラ位置へのベクトル\n",
    "        if np.dot(c_to_O, normal)>0:\n",
    "            visible_mask += face_mask[i]\n",
    "    return visible_mask!=0\n",
    "\n",
    "def compute3Dbb(obj, P):\n",
    "    # 直方体の各頂点のxyz座標を計算\n",
    "    face_idx = np.array([[0,1,5,4], # front face\n",
    "                         [1,2,6,5], # right face\n",
    "                         [2,3,7,6], # back face\n",
    "                         [3,0,4,7]]) # left face\n",
    "    ry = obj[\"rotation_y\"]\n",
    "    R = np.array([[ np.cos(ry), 0, np.sin(ry)],\n",
    "                  [          0, 1,          0],\n",
    "                  [-np.sin(ry), 0, np.cos(ry)]],\n",
    "                 dtype=np.float)\n",
    "    l = obj[\"length\"]\n",
    "    w = obj[\"width\"]\n",
    "    h = obj[\"height\"]\n",
    "    corners = np.array([[l/2, l/2, -l/2, -l/2, l/2, l/2, -l/2, -l/2],\n",
    "                        [0,0,0,0,-h,-h,-h,-h],\n",
    "                        [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2]],\n",
    "                       dtype=np.float).reshape(3,-1)\n",
    "    corner3D = np.dot(R,corners)\n",
    "    xyz = np.array([obj[\"x\"], obj[\"y\"], obj[\"z\"]], dtype=np.float).reshape([3,1])\n",
    "    corner3D += xyz\n",
    "    \n",
    "    # 直方体の各頂点が見えているかどうかを判定\n",
    "    visible_corner_flag = selectVisiblePoint(corner3D) # 見える頂点を判定\n",
    "    corner_coord2D = projectToImage(corner3D, P) # 画像座標に変換\n",
    "    \n",
    "    # 直方体の面の座標、面が見えているかどうかを判定\n",
    "    visible_surface_flag, surface_coord3D = selectVisibleSurface(corner3D)\n",
    "    surface_coord2D = projectToImage(surface_coord3D, P)\n",
    "    \n",
    "    if xyz[2]<0.1:\n",
    "        return []\n",
    "    else:\n",
    "        return visible_corner_flag, corner_coord2D, visible_surface_flag, surface_coord2D\n",
    "\n",
    "def getP2(img_name):\n",
    "    calib_path = \"../data/training/calib/\"\n",
    "    _, _, P2, _, _, _, _ = readCalib(img_name, calib_path)\n",
    "    return P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_SCALE = 4\n",
    "IMG_WIDTH = 1280 // RESIZE_SCALE\n",
    "IMG_HEIGHT = IMG_WIDTH // 16 * 5 #400\n",
    "MODEL_SCALE = 4\n",
    "\n",
    "def preprocess_image(img, training=False):\n",
    "    #画像サイズを統一\n",
    "    img_shape = img.shape[0]//RESIZE_SCALE, img.shape[1]//RESIZE_SCALE\n",
    "    if training:\n",
    "        off_x = randint(0, IMG_WIDTH-img_shape[1])\n",
    "        off_y = randint(0, IMG_HEIGHT-img_shape[0])\n",
    "    else:\n",
    "        off_x = np.round((IMG_WIDTH-img_shape[1])/2).astype('int')\n",
    "        off_y = np.round((IMG_HEIGHT-img_shape[0])/2).astype('int')\n",
    "    \n",
    "    img_dummy = np.zeros([IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    resize_img = cv2.resize(img, (img_shape[1], img_shape[0]))\n",
    "    img_dummy[off_y:off_y+img_shape[0], off_x:off_x+img_shape[1]] = resize_img\n",
    "    return (img_dummy / 255).astype('float32'), (off_x, off_y)\n",
    "\n",
    "def get_mask_and_regr(img_name, annotations_list, offset=(0,0)):\n",
    "    \n",
    "    ## mask data\n",
    "    # idx 0 : vehicle\n",
    "    # idx 1 : front and rear side\n",
    "    # idx 2 : right and left side\n",
    "    # idx 3 : 3D corner\n",
    "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 4], dtype='float32')\n",
    "    ## size of the vehicle : width, height\n",
    "    regr_size = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 2], dtype='float32')\n",
    "    ## offset for 3D detection\n",
    "    # idx 0,6 : offset from vehicle center to front or rear surface | x, y\n",
    "    # idx 1,7 : offset from vehicle center to right or left surface | x, y\n",
    "    # idx 2~5,8~11 : offset from surface(front, rear , right, or left) to each 3D corner\n",
    "    #                                                               | rb_x, lb_x, lt_x, rt_x, ..., rt_y\n",
    "    regr_3D = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 12], dtype='float32')\n",
    "    \n",
    "    annotations = annotations_list[annotations_list[\"img_name\"]==img_name]\n",
    "\n",
    "    P2 = getP2(img_name)\n",
    "    \n",
    "    target_type = ['Car', 'Van', 'Truck']\n",
    "\n",
    "    # annotationを遠い順に並び替え\n",
    "    annos = []\n",
    "    for _, anno in annotations.iterrows():\n",
    "        annos.append(anno)\n",
    "    annos_sorted = sorted(annos, key=lambda x:x['z'], reverse=True)\n",
    "    \n",
    "    for anno in annos_sorted:\n",
    "        if anno[\"type\"] in target_type:\n",
    "            ## center pointの学習データを作成 \n",
    "            # annotationをx, y, width, heightに変換\n",
    "            x = (anno[\"left\"]+anno[\"right\"])/2 / MODEL_SCALE\n",
    "            y = (anno[\"top\"]+anno[\"bottom\"])/2 / MODEL_SCALE\n",
    "            width = (anno[\"right\"]-anno[\"left\"]) / MODEL_SCALE\n",
    "            height = (anno[\"bottom\"]-anno[\"top\"]) / MODEL_SCALE\n",
    "            \n",
    "            x = x / RESIZE_SCALE\n",
    "            y = y / RESIZE_SCALE\n",
    "            \n",
    "            x = x+offset[0]/ MODEL_SCALE\n",
    "            y = y+offset[1]/ MODEL_SCALE\n",
    "            \n",
    "            width = width / RESIZE_SCALE\n",
    "            height = height / RESIZE_SCALE\n",
    "\n",
    "            ## corner, surfaceの座標を計算\n",
    "            try: # 前後距離が小さいものは無視\n",
    "                vsbl_cnr_flg, cnr, vsbl_sfc_flg, sfc = compute3Dbb(anno, P2)\n",
    "            except:\n",
    "                continue\n",
    "            cnr[0] = (cnr[0]/RESIZE_SCALE + offset[0])/MODEL_SCALE\n",
    "            cnr[1] = (cnr[1]/RESIZE_SCALE + offset[1])/MODEL_SCALE\n",
    "            sfc[0] = (sfc[0]/RESIZE_SCALE + offset[0])/MODEL_SCALE\n",
    "            sfc[1] = (sfc[1]/RESIZE_SCALE + offset[1])/MODEL_SCALE\n",
    "            \n",
    "            w = max(width,1)\n",
    "            h = max(height,1)\n",
    "            left = np.round(max(min(x-w/2,np.min(cnr[0])),0)).astype('int')\n",
    "            top = np.round(max(min(y-h/2,np.min(cnr[1])),0)).astype('int')\n",
    "            right = np.round(min(max(x+w/2,np.max(cnr[0])),IMG_WIDTH // MODEL_SCALE)).astype('int')\n",
    "            bottom = np.round(min(max(y+h/2,np.max(cnr[1])),IMG_HEIGHT // MODEL_SCALE)).astype('int')\n",
    "            hm = get_heatmap(right-left, bottom-top, w/2, h/2)\n",
    "            \n",
    "            # 隠れている車両の正解データを消去(maskのみ)\n",
    "            pts = cv2.convexHull(np.round(cnr).T.astype(np.int32))\n",
    "            cv2.fillConvexPoly(mask, points=pts, color=0)\n",
    "\n",
    "            # x, y, width, heightからmask, regrを作成\n",
    "            mask[top:bottom, left:right, 0] = hm\n",
    "            regr_size[top:bottom, left:right, 0] = width\n",
    "            regr_size[top:bottom, left:right, 1] = height\n",
    "            \n",
    "            # cregressionデータの初期化\n",
    "            nums = np.arange(0,right-left,1)\n",
    "            nums = np.tile(nums,6).reshape(6,right-left).T\n",
    "            nums = np.tile(nums,(bottom-top,1)).reshape(bottom-top,right-left,6)\n",
    "            regr_3D[top:bottom, left:right,:6] = nums\n",
    "            nums = np.arange(0,bottom-top,1)\n",
    "            nums = np.tile(nums,6).reshape(6,bottom-top).T\n",
    "            nums = np.tile(nums,right-left).reshape(bottom-top,right-left,6)\n",
    "            regr_3D[top:bottom, left:right,6:] = nums\n",
    "            \n",
    "            # \n",
    "            face_idx = np.array([[0,1,5,4], # front face\n",
    "                                 [1,2,6,5], # right face\n",
    "                                 [2,3,7,6], # back face\n",
    "                                 [3,0,4,7]]) # left face\n",
    "            ## front, rear\n",
    "            mask_FaR = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "            for i in range(0,5,2):\n",
    "                if i < 4 and vsbl_sfc_flg[i]==1:\n",
    "                    # front, rear中心へのregressionを設定\n",
    "                    regr_3D[top:bottom, left:right,0] -= (sfc[0,i]-left) # xベクトル\n",
    "                    regr_3D[top:bottom, left:right,6] -= (sfc[1,i]-top) # yベクトル\n",
    "                    \n",
    "                    # front, rear中心から側面の4点へのregressionを設定\n",
    "                    sfc_cnr = cnr[:,face_idx[i]] # 側面の四角形の座標\n",
    "                    mask_FaR = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "                    cv2.fillConvexPoly(mask_FaR, points=np.round(sfc_cnr).T.astype(np.int32), color=1)\n",
    "                    # regressionのoffsetを計算\n",
    "                    for j in range(4):\n",
    "                        regr_3D[:,:,j+2] -= (sfc_cnr[0,j]-left) * mask_FaR\n",
    "                        regr_3D[:,:,j+2+6] -= (sfc_cnr[1,j]-top) * mask_FaR\n",
    "                    break\n",
    "                elif i==4:\n",
    "                    # frontもrearも見えていなかったら\n",
    "                    regr_3D[top:bottom, left:right,0] = 0 # xベクトル\n",
    "                    regr_3D[top:bottom, left:right,6] = 0 # yベクトル\n",
    "            # right, left\n",
    "            for i in range(1,6,2):\n",
    "                if i < 5 and vsbl_sfc_flg[i]==1:\n",
    "                    regr_3D[top:bottom, left:right,1] -= (sfc[0,i]-left) # xベクトル\n",
    "                    regr_3D[top:bottom, left:right,7] -= (sfc[1,i]-top) # yベクトル\n",
    "                    \n",
    "                    # right, left中心から側面の4点へのregressionを設定\n",
    "                    sfc_cnr = cnr[:,face_idx[i]] # 側面の四角形の座標\n",
    "                    mask_RaL = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "                    cv2.fillConvexPoly(mask_RaL, points=np.round(sfc_cnr).T.astype(np.int32), color=1)\n",
    "                    mask_RaL = mask_RaL * (1-mask_FaR)\n",
    "                    # regressionのoffsetを計算\n",
    "                    for j in range(4):\n",
    "                        regr_3D[:,:,j+2] -= (sfc_cnr[0,j]-left) * mask_RaL\n",
    "                        regr_3D[:,:,j+2+6] -= (sfc_cnr[1,j]-top) * mask_RaL\n",
    "                    break\n",
    "                elif i==5:\n",
    "                    # rightもleftも見えていなかったら\n",
    "                    regr_3D[top:bottom, left:right,1] = 0 # xベクトル\n",
    "                    regr_3D[top:bottom, left:right,7] = 0 # yベクトル\n",
    "\n",
    "            # cornerのmaskを作成\n",
    "            cnr = cnr[:,vsbl_cnr_flg]\n",
    "            cnr = np.round(cnr).astype('int')\n",
    "            if w > 3:\n",
    "                for i in range(cnr.shape[1]):\n",
    "                    if 0 <= cnr[1,i] and cnr[1,i] < mask.shape[0] and\\\n",
    "                       0 <= cnr[0,i] and cnr[0,i] < mask.shape[1]:\n",
    "                        # 画像外だったら何もしない\n",
    "                        mask[cnr[1,i],cnr[0,i],3] = 1\n",
    "            # surfaceのmaskを作成\n",
    "            sfc = np.round(sfc).astype('int')\n",
    "            if w > 3:\n",
    "                for i in range(4):\n",
    "                    if 0 <= sfc[1,i] and sfc[1,i] < mask.shape[0] and \\\n",
    "                       0 <= sfc[0,i] and sfc[0,i] < mask.shape[1] and \\\n",
    "                       vsbl_sfc_flg[i]==1:\n",
    "                        # 画像外だったら何もしない\n",
    "                        if i%2==0: # 前後面のmaskを設定\n",
    "                            mask[sfc[1,i],sfc[0,i],1] = 1\n",
    "                        elif mask_FaR[sfc[1,i],sfc[0,i]]==0: # 左右面のregressionが上書きされていたらmaskを設定しない\n",
    "                            mask[sfc[1,i],sfc[0,i],2] = 1\n",
    "    return mask, regr_size, regr_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_path(img_name_list):\n",
    "    for i in range(len(img_name_list)):\n",
    "        img_name_list[i] = PATH + \"image_2/\" + img_name_list[i] + \".png\"\n",
    "        return img_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_name = train_list[8]\n",
    "img_name_list = get_img_path([img_name])\n",
    "img = plt.imread(img_name_list[0])\n",
    "img, offset = preprocess_image(img)\n",
    "mask, regr_size, regr_3D = get_mask_and_regr(img_name, annotations_list, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ生成のためのclassを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_list, annotation, root_dir, training=True):\n",
    "        self.data_list = data_list\n",
    "        self.anno = annotation\n",
    "        self.root_dir = root_dir\n",
    "        self.training = training\n",
    "        \n",
    "        self.anno = pd.read_pickle(ANNOTATIONS)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get data\n",
    "        img_name = self.data_list[idx]\n",
    "        img_path = self.root_dir + \"image_2/\" + img_name + \".png\"\n",
    "        img = plt.imread(img_path)\n",
    "        img, offset = preprocess_image(img, self.training)\n",
    "        \n",
    "        if self.training:\n",
    "            mask, regr_size, regr_3D = get_mask_and_regr(img_name, self.anno, offset)\n",
    "            # Augmentation\n",
    "            fliplr = rand()>.5\n",
    "            if fliplr:\n",
    "                img, mask, regr_size, regr_3D = img[:,::-1], mask[:,::-1], regr_size[:,::-1], regr_3D[:,::-1]\n",
    "                regr_3D[:,:,0:6] *= -1\n",
    "                regr_3D = regr_3D[:,:,[0,1,3,2,5,4,6,7,9,8,11,10]] # corner regressionを左下から時計回りに修正\n",
    "            fliptb = rand()>.5\n",
    "            if fliptb and False:\n",
    "                img, mask, regr_size, regr_3D = img[::-1], mask[::-1], regr_size[::-1], regr_3D[::-1]\n",
    "                regr_3D[:,:,6:] *= -1\n",
    "                regr_3D = regr_3D[:,:,[0,1,5,4,3,2,6,7,11,10,9,8]] # corner regressionを左下から時計回りに修正\n",
    "            \n",
    "            # 配列の向き？を入れ替える\n",
    "            mask = np.rollaxis(mask, 2, 0)\n",
    "            regr_size = np.rollaxis(regr_size, 2, 0)\n",
    "            regr_3D = np.rollaxis(regr_3D, 2, 0)\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "            \n",
    "        if self.training:\n",
    "            return [img.copy(), mask.copy(), regr_size.copy(), regr_3D.copy()]\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CarDataset(train_list, annotations_list, PATH, training=True)\n",
    "val_dataset = CarDataset(val_list, annotations_list, PATH, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create data generators - they will produce batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # for padding issues, see \n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        if x2 is not None:\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        else:\n",
    "            x = x1\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "def get_mesh(batch_size, shape_x, shape_y):\n",
    "    mg_x, mg_y = np.meshgrid(np.linspace(0, 1, shape_y), np.linspace(0, 1, shape_x))\n",
    "    mg_x = np.tile(mg_x[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
    "    mg_y = np.tile(mg_y[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
    "    mesh = torch.cat([torch.tensor(mg_x).to(device), torch.tensor(mg_y).to(device)], 1)\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_(EfficientNet):\n",
    "    \n",
    "    def extract_features_midconv(self, inputs):\n",
    "        out = []\n",
    "        \n",
    "        x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
    "        \n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            y = block(x, drop_connect_rate=drop_connect_rate)\n",
    "            if y.size()[-1] != x.size()[-1]:\n",
    "                out.append(x)\n",
    "            x = y\n",
    "            \n",
    "        x = self._swish(self._bn1(self._conv_head(x)))\n",
    "        out.append(x)\n",
    "        \n",
    "        return out[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyUNet(nn.Module):\n",
    "    '''Mixture of previous classes'''\n",
    "    def __init__(self, n_classes):\n",
    "        super(MyUNet, self).__init__()\n",
    "        self.base_model = EfficientNet_.from_pretrained('efficientnet-b0')\n",
    "        \n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.up1 = up(1282 + 112, 256)\n",
    "        self.up2 = up(256 + 40, 128)\n",
    "        self.up3 = up(128 + 24, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x2, x3, x4, x5 = self.base_model.extract_features_midconv(x)\n",
    "        \n",
    "        # Add positional info\n",
    "        mesh2 = get_mesh(batch_size, x5.shape[2], x5.shape[3])\n",
    "        x5 = torch.cat([x5, mesh2], 1)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "# Gets the GPU if there is one, otherwise the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "## MyUNetの出力ベクトル長を設定\n",
    "model = MyUNet(18).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                              mode='min',\n",
    "                              factor=0.1,\n",
    "                              patience=1,\n",
    "                              verbose=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_size = 0.01\n",
    "lambda_3D = 0.1\n",
    "\n",
    "def criterion(prediction, mask, regr_size, regr_3D):\n",
    "    # Binary mask loss\n",
    "    pred_mask = torch.sigmoid(prediction[:, 0:4])\n",
    "    mask_loss = mask * torch.log(pred_mask + 1e-12) + (1 - mask) * torch.log(1 - pred_mask + 1e-12)\n",
    "    mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    # Regression size loss\n",
    "    pred_regr = prediction[:, 4:6]\n",
    "    size_loss = (torch.abs(pred_regr - regr_size).sum(1) * mask[:,0]).sum(1).sum(1)# / (mask.sum(1).sum(1) + 1)\n",
    "    size_loss = size_loss.mean(0)\n",
    "    \n",
    "    # Regression 3D loss\n",
    "    pred_regr = prediction[:,[6,7,12,13]]\n",
    "    regr = regr_3D[:,[0,1,6,7]]\n",
    "    sfc_loss = (torch.abs(pred_regr - regr).sum(1) * mask[:,0]).sum(1).sum(1)# / (mask.sum(1).sum(1) + 1)\n",
    "    sfc_loss = sfc_loss.mean(0)\n",
    "    pred_regr = prediction[:,[8,9,10,11,14,15,16,17]]\n",
    "    regr = regr_3D[:,[2,3,4,5,8,9,10,11]]\n",
    "    cnr_loss = (torch.abs(pred_regr - regr).sum(1) * (mask[:,1]+mask[:,2])).sum(1).sum(1)# / (mask.sum(1).sum(1) + 1)\n",
    "    cnr_loss = cnr_loss.mean(0)\n",
    "    \n",
    "    return mask_loss, lambda_size*size_loss, lambda_3D*(sfc_loss+cnr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNE_EPOCH = 35\n",
    "\n",
    "def train_model(epoch, history=None):\n",
    "    model.train()\n",
    "    train_mask_loss = 0\n",
    "    train_regr_size_loss = 0\n",
    "    train_regr_3D_loss = 0\n",
    "    \n",
    "    for batch_idx, (img_batch, mask_batch, regr_size_batch, regr_3D_batch) in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "        img_batch = img_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        regr_size_batch = regr_size_batch.to(device)\n",
    "        regr_3D_batch = regr_3D_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(img_batch)\n",
    "        mask_loss, regr_size_loss, regr_3D_loss =\\\n",
    "            criterion(output, mask_batch, regr_size_batch, regr_3D_batch)\n",
    "        loss = mask_loss + regr_size_loss + regr_3D_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        train_mask_loss += mask_loss.detach()\n",
    "        train_regr_size_loss += regr_size_loss.detach()\n",
    "        train_regr_3D_loss += regr_3D_loss.detach()\n",
    "    \n",
    "    train_mask_loss /= len(train_dataset)\n",
    "    train_regr_size_loss /= len(train_dataset)\n",
    "    train_regr_3D_loss /= len(train_dataset)\n",
    "    train_loss = train_mask_loss + train_regr_size_loss + train_regr_3D_loss\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'train_mask_loss'] = train_mask_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'train_regr_size_loss'] = train_regr_size_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'train_regr_3D_loss'] = train_regr_3D_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'train_loss'] = train_loss.data.cpu().numpy()\n",
    "        \n",
    "    print('Train Epoch: {} \\tLR: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "        epoch,\n",
    "        optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "        train_loss))\n",
    "\n",
    "def evaluate_model(epoch, history=None):\n",
    "    model.eval()\n",
    "    val_mask_loss = 0\n",
    "    val_regr_size_loss = 0\n",
    "    val_regr_3D_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_batch, mask_batch, regr_size_batch, regr_3D_batch in val_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            mask_batch = mask_batch.to(device)\n",
    "            regr_size_batch = regr_size_batch.to(device)\n",
    "            regr_3D_batch = regr_3D_batch.to(device)\n",
    "\n",
    "            output = model(img_batch)\n",
    "\n",
    "            mask_loss, regr_size_loss, regr_3D_loss =\\\n",
    "                criterion(output, mask_batch, regr_size_batch, regr_3D_batch)\n",
    "                    \n",
    "            val_mask_loss += mask_loss.detach()\n",
    "            val_regr_size_loss += regr_size_loss.detach()\n",
    "            val_regr_3D_loss += regr_3D_loss.detach()\n",
    "    \n",
    "    val_mask_loss /= len(val_dataset)\n",
    "    val_regr_size_loss /= len(val_dataset)\n",
    "    val_regr_3D_loss /= len(val_dataset)\n",
    "    val_loss = val_mask_loss + val_regr_size_loss + val_regr_3D_loss\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'val_mask_loss'] = val_mask_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'val_regr_size_loss'] = val_regr_size_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'val_regr_3D_loss'] = val_regr_3D_loss.data.cpu().numpy()\n",
    "        history.loc[epoch, 'val_loss'] = val_loss.data.cpu().numpy()\n",
    "    \n",
    "    print('Val loss: {:.4f}'.format(val_loss))\n",
    "    \n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/445 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model parameters are FREEZED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:26<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLR: 0.100000\tLoss: 11.113677\n",
      "Val loss: 49.2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:20<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLR: 0.100000\tLoss: 8.682487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 8.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:26<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 \tLR: 0.100000\tLoss: 8.110178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 7.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:17<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 \tLR: 0.100000\tLoss: 7.819742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.9497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:42<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 \tLR: 0.100000\tLoss: 7.537059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:46<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 \tLR: 0.100000\tLoss: 7.383341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.9381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:43<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 \tLR: 0.100000\tLoss: 7.236883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.5494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:39<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 \tLR: 0.100000\tLoss: 7.105668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:37<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 \tLR: 0.100000\tLoss: 6.995458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.3813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:35<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 \tLR: 0.100000\tLoss: 6.918099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:21<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 \tLR: 0.100000\tLoss: 6.819230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:09<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 \tLR: 0.100000\tLoss: 6.748757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:11<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 \tLR: 0.100000\tLoss: 6.678144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:16<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 \tLR: 0.100000\tLoss: 6.613383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [10:27<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 \tLR: 0.100000\tLoss: 6.524183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [10:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 \tLR: 0.100000\tLoss: 6.493692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 6.0172\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:27<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 \tLR: 0.010000\tLoss: 6.132767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:28<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 \tLR: 0.010000\tLoss: 6.032299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:33<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 \tLR: 0.010000\tLoss: 6.026545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:29<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 \tLR: 0.010000\tLoss: 5.980632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:29<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 \tLR: 0.010000\tLoss: 5.947254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:26<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 \tLR: 0.010000\tLoss: 5.924675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.5315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:24<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 \tLR: 0.010000\tLoss: 5.896248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:26<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 \tLR: 0.010000\tLoss: 5.847919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:30<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 \tLR: 0.010000\tLoss: 5.915067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:29<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 \tLR: 0.010000\tLoss: 5.816315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:30<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 \tLR: 0.010000\tLoss: 5.800001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4741\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:29<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 \tLR: 0.001000\tLoss: 5.753996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:31<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 \tLR: 0.001000\tLoss: 5.756733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:31<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 \tLR: 0.001000\tLoss: 5.730113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:31<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 \tLR: 0.001000\tLoss: 5.720052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:30<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 \tLR: 0.001000\tLoss: 5.742278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:31<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 \tLR: 0.001000\tLoss: 5.731576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:28<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 \tLR: 0.001000\tLoss: 5.721322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [09:28<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 \tLR: 0.001000\tLoss: 5.738112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.4365\n",
      "Base model parameters are UNFREEZED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:49<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 \tLR: 0.001000\tLoss: 6.130186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.7689\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:50<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 \tLR: 0.000100\tLoss: 5.820702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:46<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 \tLR: 0.000100\tLoss: 5.724500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:47<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 \tLR: 0.000100\tLoss: 5.642127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:49<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 \tLR: 0.000100\tLoss: 5.588252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:52<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 \tLR: 0.000100\tLoss: 5.543706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:49<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 \tLR: 0.000100\tLoss: 5.505436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:49<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 \tLR: 0.000100\tLoss: 5.485123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:55<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 \tLR: 0.000100\tLoss: 5.447570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:52<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 \tLR: 0.000100\tLoss: 5.398481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:51<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 \tLR: 0.000100\tLoss: 5.409877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [16:53<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46 \tLR: 0.000100\tLoss: 5.349324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 299/445 [11:32<05:38,  2.32s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4c5f2e0add70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b5396030be32>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epoch, history)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr_size_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr_3D_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregr_size_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregr_3D_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "history = pd.DataFrame()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch == 0:\n",
    "        print(\"Base model parameters are FREEZED.\")\n",
    "        for param in model.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif epoch == FINE_TUNE_EPOCH:\n",
    "        print(\"Base model parameters are UNFREEZED.\")\n",
    "        for param in model.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train_model(epoch, history)\n",
    "    evaluate_model(epoch, history)\n",
    "    torch.save(model.state_dict(), '../models/model_' + str(epoch) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/model.pth')\n",
    "model_cpu = model.to('cpu')\n",
    "torch.save(model_cpu.state_dict(), '../models/model_cpu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb8961a0a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.dropna()['train_loss']\n",
    "val_loss = history.dropna()['val_loss']\n",
    "plt.scatter(train_loss.index[2:], train_loss[2:])\n",
    "plt.scatter(val_loss.index[2:], val_loss[2:])\n",
    "plt.legend([\"train_loss\", \"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb89612fb38>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mask_loss = history.dropna()['train_mask_loss']\n",
    "train_regr_size_loss = history.dropna()['train_regr_size_loss']\n",
    "train_regr_3D_loss = history.dropna()['train_regr_3D_loss']\n",
    "plt.scatter(train_loss.index[2:], train_mask_loss[2:])\n",
    "plt.scatter(train_loss.index[2:], train_regr_size_loss[2:])\n",
    "plt.scatter(train_loss.index[2:], train_regr_3D_loss[2:])\n",
    "plt.legend([\"'train_mask_loss'\", \"train_regr_size_loss\", \"train_regr_3D_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb8960b07b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_mask_loss = history.dropna()['val_mask_loss']\n",
    "val_regr_size_loss = history.dropna()['val_regr_size_loss']\n",
    "val_regr_3D_loss = history.dropna()['val_regr_3D_loss']\n",
    "plt.scatter(val_loss.index[2:], val_mask_loss[2:])\n",
    "plt.scatter(val_loss.index[2:], val_regr_size_loss[2:])\n",
    "plt.scatter(val_loss.index[2:], val_regr_3D_loss[2:])\n",
    "plt.legend([\"'val_mask_loss'\", \"val_regr_size_loss\", \"val_regr_3D_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = MyUNet(18)\n",
    "m.eval()\n",
    "m_state_dict = torch.load(\"../models/model.pth\")\n",
    "m.load_state_dict(m_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, mask, regr, cnr, regr_cnr = val_dataset[0]\n",
    "img2 = np.rollaxis(img, 0, 3)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(img2*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(torch.tensor(img[None]).to(device))\n",
    "logits = output[0,0].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Model predictions')\n",
    "plt.imshow(logits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(torch.tensor(img[None]).to(device))\n",
    "logits = output[0,3].data.cpu().numpy()\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Model predictions')\n",
    "plt.imshow(logits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(torch.tensor(img[None]).to(device))\n",
    "logits = output[0,4].data.cpu().numpy()\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Model predictions')\n",
    "plt.imshow(logits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
